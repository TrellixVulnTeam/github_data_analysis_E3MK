{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load sample.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_file(path, verbose=False, final_type=np.uint64):\n",
    "    ## PullRequest\n",
    "    data = pd.read_csv(path+'PullRequestEvent-data.csv', index_col='Unnamed: 0')\n",
    "\n",
    "    pr_closed_count = data[data['payload.action'] == 'closed'].groupby('repo.id').count().iloc[:, [1]]\n",
    "    pr_closed_count.columns = ['pr_closed_count']\n",
    "\n",
    "    pr_opened_count = data[data['payload.action'].isin(['opened', 'reopened'])].groupby('repo.id').count().iloc[:, [1]]\n",
    "    pr_opened_count.columns = ['pr_opened_count']\n",
    "\n",
    "    ## Pull request Comments\n",
    "    data  = pd.read_csv(path+'PullRequestReviewCommentEvent-data.csv', index_col='Unnamed: 0')\n",
    "\n",
    "    comment_pr_count = data[data['payload.action'] == 'created'].groupby('repo.id').count().iloc[:, [1]]\n",
    "    comment_pr_count.columns = ['comment_pr_count']\n",
    "\n",
    "    #comment_by_owner_count = data[data['payload.action'] == ['created'] & ].groupby('repo.id').count().iloc[:, [1]]\n",
    "    \n",
    "    ## Comments\n",
    "    data  = pd.read_csv(path+'IssueCommentEvent-data.csv', index_col='Unnamed: 0')\n",
    "    comment_issue_count = data[data['payload.action'] == 'created'].groupby('repo.id').count().iloc[:, [1]]\n",
    "    comment_issue_count.columns = ['comment_pr_count']\n",
    "    \n",
    "    ## Push\n",
    "    data  = pd.read_csv(path+'PushEvent-data.csv', index_col='Unnamed: 0')\n",
    "\n",
    "    push_count = data.groupby('repo.id').count().iloc[:, [1]]\n",
    "    push_count.columns = ['push_count']\n",
    "\n",
    "    total_push_size = data[['repo.id', 'payload.size']].groupby('repo.id').sum()\n",
    "    total_push_size.columns = ['total_push_size']\n",
    "\n",
    "    ## Forks\n",
    "    data  = pd.read_csv(path+'ForkEvent-data.csv', index_col='Unnamed: 0')\n",
    "    fork_count = data.groupby('repo.id').count().iloc[:, [1]]\n",
    "    fork_count.columns = ['fork_count']\n",
    "\n",
    "    ## Issues\n",
    "    data  = pd.read_csv(path+'IssuesEvent-data.csv', index_col='Unnamed: 0')\n",
    "\n",
    "    issue_closed_count = data[data['payload.action'] == 'closed'].groupby('repo.id').count().iloc[:, [1]]\n",
    "    issue_closed_count.columns = ['issue_closed_count']\n",
    "\n",
    "    issue_opened_count = data[data['payload.action'].isin(['opened', 'reopened'])].groupby('repo.id').count().iloc[:, [1]]\n",
    "    issue_opened_count.columns = ['issue_opened_count']\n",
    "\n",
    "    # Watch\n",
    "    data  = pd.read_csv(path+'WatchEvent-data.csv', index_col='Unnamed: 0')\n",
    "\n",
    "    new_watch_count = data[data['payload.action'] == 'started'].groupby('repo.id').count().iloc[:, [1]]\n",
    "    new_watch_count.columns = ['new_watch_count']\n",
    "\n",
    "    # Create\n",
    "    data  = pd.read_csv(path+'CreateEvent-data.csv', index_col='Unnamed: 0')\n",
    "\n",
    "    new_branch_count = data[data['payload.ref_type'] == 'branch'].groupby('repo.id').count().iloc[:, [1]]\n",
    "    new_branch_count.columns = ['new_branch_count']\n",
    "\n",
    "    new_tag_count = data[data['payload.ref_type'] == 'tag'].groupby('repo.id').count().iloc[:, [1]]\n",
    "    new_tag_count.columns = ['new_tag_count']\n",
    "\n",
    "\n",
    "    ## Merging everything\n",
    "    dfs = [pr_closed_count, pr_opened_count, comment_pr_count, push_count, total_push_size, \n",
    "           fork_count, issue_closed_count,issue_opened_count, new_watch_count, new_branch_count, new_tag_count]\n",
    "\n",
    "\n",
    "    df_final = reduce(lambda left,right: pd.merge(left,right,how='outer', left_index=True, right_index=True).fillna(0), dfs)\n",
    "\n",
    "    df_final[:] = df_final[:].astype(final_type)\n",
    "\n",
    "    if verbose:\n",
    "        print(df_final.info())\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_preprocess_save(date, path, outpath):\n",
    "    tmp = \"tmp/\"\n",
    "    tar_path = path + date + \".tar.gz\"\n",
    "    tar = tarfile.open(tar_path)\n",
    "    tar.extractall(tmp)\n",
    "    tar.close()    \n",
    "    extracted_path = tmp + date + \"/\"\n",
    "    df = preprocess_file(extracted_path, verbose=False, final_type=np.uint64)\n",
    "    df.to_csv(outpath + date +'.csv')\n",
    "\n",
    "extract_preprocess_save('2015-02-01', \"/Users/etienne/Dropbox/NYU/DS-GA1001-IntroToDSc/project/sample_data/\", \"out/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(start_date, end_date, path, out_path):\n",
    "    dates = [d.strftime('%Y-%m-%d') for d in pd.date_range(start_date, end_date)]\n",
    "    for date in dates :\n",
    "        extract_preprocess_save(date, \"/Users/etienne/Dropbox/NYU/DS-GA1001-IntroToDSc/project/sample_data/\", \n",
    "                        out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.668201208114624\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    t1 =time.time()\n",
    "    preprocess('2015-02-01', '2015-02-01', \"/Users/etienne/Dropbox/NYU/DS-GA1001-IntroToDSc/project/sample_data/\", \"out/\")\n",
    "    t2 = time.time()\n",
    "    print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
